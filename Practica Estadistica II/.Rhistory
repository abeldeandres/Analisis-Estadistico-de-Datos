# Covariance and Correlation matrix
cov(medifis[,-1])
# Importing data sets
medifis=read.table("medifis.txt")
# Importing data sets
medifis=read.table("medifis.txt")
# Importing data sets
medifis=read.table("medifis.txt")
colnames(medifis)=c("gr","hg","wg","foot","arm","back","skull","knee")
# Importing data sets
medifis=read.table("medifis.txt")
colnames(medifis)=c("gr","hg","wg","foot","arm","back","skull","knee")
hbat=read.csv("hbat.csv",header=TRUE,sep=",")
---
title: "Practica"
output: html_document
---
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
summary(cars)
```
You can also embed plots, for example:
```{r, echo=FALSE}
plot(cars)
# Needed for OutOfMemoryError: Java heap space
library(rJava)
#.jinit(parameters="-Xmx4g")
#.jinit(parameters="-Xmx1024m")
options(java.parameters = "-Xmx1000m")
# If there are more memory problems, invoke gc() after the POS tagging
library(openNLP)
library(openNLPmodels.en)
library(tm)
getAnnotationsFromDocument = function(doc){
x=as.String(doc)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))
y2 <- annotate(x, pos_tag_annotator, y1)
parse_annotator <- Parse_Annotator()
y3 <- annotate(x, parse_annotator, y2)
return(y3)
}
getAnnotatedMergedDocument = function(doc,annotations){
x=as.String(doc)
y2w <- subset(annotations, type == "word")
tags <- sapply(y2w$features, '[[', "POS")
r1 <- sprintf("%s/%s", x[y2w], tags)
r2 <- paste(r1, collapse = " ")
return(r2)
}
getAnnotatedPlainTextDocument = function(doc,annotations){
x=as.String(doc)
a = AnnotatedPlainTextDocument(x,annotations)
return(a)
}
source.pos = DirSource("review_polarity/txt_sentoken/pos", encoding = "UTF-8")
corpus = Corpus(source.pos)
source.pos = DirSource("review_polarity/txt_sentoken/pos", encoding = "UTF-8")
return(a)
}
source.pos = DirSource("review_polarity/txt_sentoken/pos", encoding = "UTF-8")
## Basic inspection and Manipulation of a data set
# Import data from the url
url="http://lib.stat.cmu.edu/datasets/1993.expo/cereal"
cereals <- read.table(url, header=FALSE, as.is=TRUE, na.strings="-1")
names(cereals) <- c('name','mfr','type','calories','protein','fat','sodium','fiber','carbo',
'sugars','shelf','potass','vitamins','weight','cups')
# or from local file
cereals <- read.table(cereal.txt, header=FALSE, as.is=TRUE, na.strings="-1")
# structure of the data set
str(cereals)
getwd()
setwd("C:/Users/abelillo/Dropbox/Abel y GermÃ¡n/Practica Estadistica II")
library(readxl)
library(forecast)
library(astsa)
library(tseries)
require(forecast)
Datos_g8 <- read_excel('Datos_g8.xlsx')
data.ts=ts(Datos_g8$`Tasa paro`, start=c(1987,6), end=c(2013,9), frequency=4)
plot(data.ts, ylab="TasaParo", xlab="Tiempo")
